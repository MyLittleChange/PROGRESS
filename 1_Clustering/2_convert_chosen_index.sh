#!/bin/bash
#SBATCH --job-name=convert_chosen_index
#SBATCH --output=convert_chosen_index_output.txt
#SBATCH --error=convert_chosen_index_error.txt
#SBATCH --ntasks=1

# ============================================================
# Convert Clustering Indices to JSON
# Uses two different clustering results:
#   - 1000 centers: for annotating all samples with cluster IDs
#   - 5000 centers: for selecting top 50K/60K warm-up samples
# ============================================================

# Configuration - modify these paths for your setup
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="${SCRIPT_DIR}/../.."  # PROGRESS directory
UTILS_DIR="${PROJECT_ROOT}/utils"   # Path to utils directory

# Data paths - SET THESE
LLAVA_DATA_PATH=""      # Path to original data JSON (e.g., llava_v1_5_mix665k.json)
OUTPUT_DIR=""           # Directory to save output JSON files
CLUSTERING_DIR=""       # Base directory containing clustering outputs

# Feature type and sample ratios (should match 0_clustering_dino_bert.sh)
FEATURE_TYPE="dino-bert"
SAMPLE_RATIO_50K=0.075
SAMPLE_RATIO_60K=0.09

# Centroid counts (should match 0_clustering_dino_bert.sh)
NCENTROIDS_ANNOTATION=1000   # For annotating all samples
NCENTROIDS_SELECTION=5000    # For selecting warm-up samples

# Paths to clustering outputs
# 1000 centers - for annotation
CLUSTERING_DIR_1K="${CLUSTERING_DIR}/${NCENTROIDS_ANNOTATION}_msa_save_folder_${FEATURE_TYPE}"
NEAREST_CENTROID_1K="${CLUSTERING_DIR_1K}/nearest_cent.npy"
DIST_TO_CENT_1K="${CLUSTERING_DIR_1K}/dist_to_cent.npy"

# 5000 centers - for selection
CLUSTERING_DIR_5K="${CLUSTERING_DIR}/${NCENTROIDS_SELECTION}_msa_save_folder_${FEATURE_TYPE}"
NEAREST_CENTROID_5K="${CLUSTERING_DIR_5K}/nearest_cent.npy"
DIST_TO_CENT_5K="${CLUSTERING_DIR_5K}/dist_to_cent.npy"

# Paths to indices files (generated by 0_clustering_dino_bert.sh using 5000 centers)
INDICES_50K="${CLUSTERING_DIR}/selected_indices_${SAMPLE_RATIO_50K}_${FEATURE_TYPE}.npy"
INDICES_60K="${CLUSTERING_DIR}/selected_indices_${SAMPLE_RATIO_60K}_${FEATURE_TYPE}.npy"

# Output JSON paths
OUTPUT_WITH_CLUSTER_ID="${OUTPUT_DIR}/llava_665k_with_cluster_id.json"
OUTPUT_TOP_50K="${OUTPUT_DIR}/Top_50K.json"
OUTPUT_TOP_60K="${OUTPUT_DIR}/Top_60K.json"
OUTPUT_TOP_50K_TO_60K="${OUTPUT_DIR}/Top_50K_to_60K.json"
OUTPUT_REMAINING="${OUTPUT_DIR}/Remaining_605K.json"

# Create output directory
mkdir -p "${OUTPUT_DIR}"

echo "========================================"
echo "Converting clustering indices to JSON"
echo "========================================"
echo "Using ${NCENTROIDS_ANNOTATION} centers for annotation"
echo "Using ${NCENTROIDS_SELECTION} centers for selection"
echo "========================================"

# ============================================================
# Step 0: Assign cluster IDs to ALL samples using 1000 centers
# This creates a base file with cluster_id for each sample
# ============================================================
echo ""
echo "Step 0: Assigning cluster IDs to all 665K samples (using ${NCENTROIDS_ANNOTATION} centers)..."
python ${UTILS_DIR}/COINCIDE_Indices_to_Accuracy.py \
    --llava_data_path ${LLAVA_DATA_PATH} \
    --nearest_centroid_path ${NEAREST_CENTROID_1K} \
    --dist_to_cent_path ${DIST_TO_CENT_1K} \
    --output_path ${OUTPUT_WITH_CLUSTER_ID}

# ============================================================
# Step 1: Convert Top 50K indices to JSON using 5000 centers
# Selected indices come from 5000-center clustering
# But cluster_id annotation uses 1000 centers
# ============================================================
echo ""
echo "Step 1: Converting Top 50K indices (selection from ${NCENTROIDS_SELECTION} centers, annotation from ${NCENTROIDS_ANNOTATION} centers)..."
python ${UTILS_DIR}/COINCIDE_Indices_to_Accuracy.py \
    --llava_data_path ${LLAVA_DATA_PATH} \
    --chosen_indices_path ${INDICES_50K} \
    --output_path ${OUTPUT_TOP_50K} \
    --keep_chosen_only

# ============================================================
# Step 2: Convert Top 60K indices to JSON
# ============================================================
echo ""
echo "Step 2: Converting Top 60K indices (selection from ${NCENTROIDS_SELECTION} centers, annotation from ${NCENTROIDS_ANNOTATION} centers)..."
python ${UTILS_DIR}/COINCIDE_Indices_to_Accuracy.py \
    --llava_data_path ${LLAVA_DATA_PATH} \
    --chosen_indices_path ${INDICES_60K} \
    --output_path ${OUTPUT_TOP_60K} \
    --keep_chosen_only

# ============================================================
# Step 3: Generate Top_50K_to_60K by removing Top_50K from Top_60K
# ============================================================
echo ""
echo "Step 3: Generating Top_50K_to_60K (removing Top_50K from Top_60K)..."
python ${UTILS_DIR}/concat_jsons.py \
    --file1 ${OUTPUT_TOP_60K} \
    --file2 ${OUTPUT_TOP_50K} \
    --output ${OUTPUT_TOP_50K_TO_60K} \
    --remove_samples

# ============================================================
# Step 4: Generate Remaining_605K by removing Top_60K from original 665K
# ============================================================
echo ""
echo "Step 4: Generating Remaining_605K (removing Top_60K from 665K)..."
python ${UTILS_DIR}/concat_jsons.py \
    --file1 ${OUTPUT_WITH_CLUSTER_ID} \
    --file2 ${OUTPUT_TOP_60K} \
    --output ${OUTPUT_REMAINING} \
    --remove_samples

echo ""
echo "========================================"
echo "Done! Generated:"
echo "========================================"
echo ""
echo "Base file (all samples with ${NCENTROIDS_ANNOTATION}-center cluster IDs):"
echo "  - ${OUTPUT_WITH_CLUSTER_ID}"
echo ""
echo "Warm-up data (selected using ${NCENTROIDS_SELECTION} centers, annotated with ${NCENTROIDS_ANNOTATION} centers):"
echo "  - ${OUTPUT_TOP_50K} (first warm-up: ~50K samples)"
echo "  - ${OUTPUT_TOP_60K} (warm-up total: ~60K samples)"
echo "  - ${OUTPUT_TOP_50K_TO_60K} (second warm-up: ~10K samples)"
echo ""
echo "Remaining data:"
echo "  - ${OUTPUT_REMAINING} (remaining: ~605K samples after warm-up)"
echo "========================================"
